<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLMs for Babies</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Comic Sans MS', 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }
        
        .presentation-container {
            width: 100%;
            max-width: 1200px;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            overflow: hidden;
        }
        
        .slide {
            display: none;
            padding: 60px;
            min-height: 600px;
            animation: slideIn 0.5s ease-in-out;
        }
        
        .slide.active {
            display: block;
        }
        
        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateX(30px);
            }
            to {
                opacity: 1;
                transform: translateX(0);
            }
        }
        
        h1 {
            color: #5e72e4;
            font-size: 3em;
            margin-bottom: 30px;
            text-align: center;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
        }
        
        h2 {
            color: #825ee4;
            font-size: 2.2em;
            margin-bottom: 25px;
            border-bottom: 3px solid #f0f0f0;
            padding-bottom: 10px;
        }
        
        h3 {
            color: #5e72e4;
            font-size: 1.8em;
            margin: 20px 0;
        }
        
        p, li {
            font-size: 1.3em;
            line-height: 1.8;
            color: #333;
            margin-bottom: 15px;
        }
        
        ul {
            margin-left: 30px;
            margin-bottom: 20px;
        }
        
        .neuron {
            width: 60px;
            height: 60px;
            background: #ff6b6b;
            border-radius: 50%;
            display: inline-block;
            margin: 10px;
            position: relative;
            animation: pulse 2s infinite;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
        
        .network-diagram {
            display: flex;
            justify-content: space-around;
            align-items: center;
            margin: 30px 0;
        }
        
        .layer {
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        
        .connection {
            width: 100px;
            height: 2px;
            background: #ccc;
            margin: 0 -50px;
        }
        
        .navigation {
            display: flex;
            justify-content: space-between;
            padding: 20px 60px;
            background: #f8f9fa;
            border-top: 1px solid #dee2e6;
        }
        
        button {
            background: #5e72e4;
            color: white;
            border: none;
            padding: 12px 30px;
            font-size: 1.1em;
            border-radius: 25px;
            cursor: pointer;
            transition: all 0.3s;
            font-weight: bold;
        }
        
        button:hover {
            background: #4c63d2;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(94, 114, 228, 0.3);
        }
        
        button:disabled {
            background: #ccc;
            cursor: not-allowed;
            transform: none;
        }
        
        .slide-number {
            display: flex;
            align-items: center;
            font-size: 1.1em;
            color: #666;
        }
        
        .code-block {
            background: #f7f7f7;
            border-left: 4px solid #5e72e4;
            padding: 20px;
            margin: 20px 0;
            border-radius: 8px;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
        }
        
        .highlight {
            background: #ffd93d;
            padding: 3px 8px;
            border-radius: 4px;
            font-weight: bold;
        }
        
        .emoji {
            font-size: 2em;
            margin: 0 10px;
        }
        
        .center {
            text-align: center;
        }
        
        .visual-example {
            background: #f0f8ff;
            padding: 30px;
            border-radius: 15px;
            margin: 20px 0;
            border: 2px dashed #5e72e4;
        }
        
        .token {
            display: inline-block;
            background: #e8f4ff;
            border: 2px solid #5e72e4;
            padding: 8px 15px;
            margin: 5px;
            border-radius: 20px;
            font-size: 1.2em;
        }
        
        .arrow {
            display: inline-block;
            margin: 0 10px;
            color: #5e72e4;
            font-size: 1.5em;
        }
    </style>
</head>
<body>
    <div class="presentation-container">
        <!-- Slide 1: Title Slide -->
        <div class="slide active">
            <h1>üçº LLMs for Babies üß∏</h1>
            <div class="center">
                <p style="font-size: 1.8em; color: #5e72e4; margin: 40px 0;">
                    Demystifying Large Language Models & Transformers
                </p>
                <p style="font-size: 1.4em;">
                    Making AI accessible for domain scientists
                </p>
                <div class="network-diagram">
                    <div class="neuron"></div>
                    <div class="connection"></div>
                    <div class="neuron"></div>
                    <div class="connection"></div>
                    <div class="neuron"></div>
                </div>
                <p style="margin-top: 40px; font-style: italic;">
                    "If you can't explain it simply, you don't understand it well enough"
                </p>
            </div>
        </div>

        <!-- Slide 2: Can Machines Think? -->
        <div class="slide">
            <h2>Can Machines Think? ü§î</h2>
            <h3>Richard Feynman's Perspective</h3>
            <div class="visual-example">
                <p><strong>Feynman asked:</strong> "Can machines really think like humans?"</p>
                <p>His answer: <span class="highlight">It depends on what we mean by "think"</span></p>
            </div>
            <ul>
                <li>Machines can process information</li>
                <li>They can recognize patterns</li>
                <li>They can make decisions based on rules</li>
                <li>But do they "understand" like we do? ü§∑</li>
            </ul>
            <p><strong>Key insight:</strong> Instead of asking IF machines can think, let's understand HOW they process information!</p>
        </div>

        <!-- Slide 3: Simple Neural Network -->
        <div class="slide">
            <h2>How Does a Simple Neural Network Work? üß†</h2>
            <div class="visual-example">
                <h3>Think of it like a decision-making friend!</h3>
                <div class="network-diagram">
                    <div class="layer">
                        <p>Input</p>
                        <div class="neuron"></div>
                        <div class="neuron"></div>
                    </div>
                    <div class="layer">
                        <p>Think</p>
                        <div class="neuron" style="background: #4ecdc4;"></div>
                    </div>
                    <div class="layer">
                        <p>Output</p>
                        <div class="neuron" style="background: #95e77e;"></div>
                    </div>
                </div>
            </div>
            <p><strong>Simple Example:</strong> Is it a cat or a dog?</p>
            <ul>
                <li>üëÅÔ∏è <strong>Input neurons:</strong> Look at features (ears, tail, size)</li>
                <li>üß† <strong>Hidden neurons:</strong> Combine features to make patterns</li>
                <li>‚úÖ <strong>Output neurons:</strong> Make a decision (Cat! or Dog!)</li>
            </ul>
        </div>

        <!-- Slide 4: RNN Introduction -->
        <div class="slide">
            <h2>Recurrent Neural Networks (RNNs) üîÑ</h2>
            <h3>Networks with Memory!</h3>
            <div class="visual-example">
                <p>Regular Neural Network: <span class="token">Word</span> ‚Üí <span class="token">Output</span></p>
                <p>RNN: <span class="token">Word 1</span> ‚Üí üß† ‚Üí <span class="token">Word 2</span> ‚Üí üß† ‚Üí <span class="token">Word 3</span></p>
                <p style="margin-top: 20px;">The network <strong>remembers</strong> what it saw before!</p>
            </div>
            <p><strong>Why is memory important?</strong></p>
            <ul>
                <li>Understanding "The cat sat on the ___" requires remembering "cat"</li>
                <li>Context matters in language!</li>
                <li>Each word influences understanding of the next</li>
            </ul>
        </div>

        <!-- Slide 5: Embeddings -->
        <div class="slide">
            <h2>Word Embeddings üìç</h2>
            <h3>Teaching computers what words mean</h3>
            <div class="visual-example">
                <p><strong>Problem:</strong> Computers only understand numbers!</p>
                <p><strong>Solution:</strong> Turn words into number coordinates</p>
                <div style="margin: 20px 0;">
                    <span class="token">Cat</span> <span class="arrow">‚Üí</span> <span class="token">[0.2, 0.8, 0.5]</span><br>
                    <span class="token">Dog</span> <span class="arrow">‚Üí</span> <span class="token">[0.3, 0.7, 0.6]</span><br>
                    <span class="token">Car</span> <span class="arrow">‚Üí</span> <span class="token">[0.9, 0.1, 0.2]</span>
                </div>
            </div>
            <p><strong>Magic:</strong> Similar words get similar numbers!</p>
            <p>Cat and Dog are close together, but Car is far away!</p>
        </div>

        <!-- Slide 6: Tokenization -->
        <div class="slide">
            <h2>Tokenization üî§</h2>
            <h3>Breaking text into bite-sized pieces</h3>
            <div class="visual-example">
                <p><strong>Input:</strong> "Hello world!"</p>
                <p><strong>Tokens:</strong> 
                    <span class="token">Hello</span>
                    <span class="token">world</span>
                    <span class="token">!</span>
                </p>
            </div>
            <p><strong>Why not just use letters?</strong></p>
            <ul>
                <li>Too many steps to process</li>
                <li>Loses meaning of common words</li>
            </ul>
            <p><strong>Why not whole sentences?</strong></p>
            <ul>
                <li>Too many possible combinations</li>
                <li>Can't handle new sentences</li>
            </ul>
            <p>‚ú® <strong>Tokens are just right!</strong> Like Goldilocks! üêª</p>
        </div>

        <!-- Slide 7: LSTMs -->
        <div class="slide">
            <h2>Long Short-Term Memory (LSTM) üß†üíæ</h2>
            <h3>Solving the forgetting problem</h3>
            <div class="visual-example">
                <p><strong>Problem with simple RNNs:</strong> They forget things from long ago!</p>
                <p style="margin: 20px 0;">
                    "The cat, who lived in the big house on the hill with the red roof, 
                    <span class="highlight">was sleeping</span>."
                </p>
                <p>Regular RNN might forget "cat" by the time it reaches "sleeping"!</p>
            </div>
            <p><strong>LSTM Solution: Three special gates</strong></p>
            <ul>
                <li>üö™ <strong>Forget Gate:</strong> What to throw away</li>
                <li>üíæ <strong>Input Gate:</strong> What new info to store</li>
                <li>üì§ <strong>Output Gate:</strong> What to pass forward</li>
            </ul>
        </div>

        <!-- Slide 8: Attention Mechanism -->
        <div class="slide">
            <h2>Attention Is All You Need! üëÄ</h2>
            <h3>The breakthrough that changed everything</h3>
            <div class="visual-example">
                <p><strong>Old way (RNN):</strong> Read one word at a time, in order</p>
                <p><strong>New way (Attention):</strong> Look at ALL words and focus on what's important!</p>
                <div style="margin: 20px 0; font-size: 1.4em;">
                    The <span style="opacity: 0.3">cat</span> 
                    <span style="opacity: 1; background: yellow;">sat</span> 
                    <span style="opacity: 0.3">on</span> 
                    <span style="opacity: 0.7">the</span> 
                    <span style="opacity: 1; background: yellow;">mat</span>
                </div>
                <p>When processing "sat", the model pays most attention to "cat" and "mat"!</p>
            </div>
            <p><strong>Why is this revolutionary?</strong></p>
            <ul>
                <li>‚ö° Can process all words in parallel (faster!)</li>
                <li>üéØ Can focus on relevant context</li>
                <li>üìè Handles long sequences better</li>
            </ul>
        </div>

        <!-- Slide 9: The Transformer -->
        <div class="slide">
            <h2>The Transformer ü§ñ</h2>
            <h3>The architecture behind ChatGPT, Claude, and more!</h3>
            <div class="visual-example">
                <h3>Key Components:</h3>
                <p><strong>1. Self-Attention:</strong> Words look at each other</p>
                <p><strong>2. Multi-Head Attention:</strong> Look at relationships from multiple perspectives</p>
                <p><strong>3. Position Encoding:</strong> Remember word order without RNN</p>
                <p><strong>4. Feed-Forward Networks:</strong> Process the attended information</p>
            </div>
            <p><strong>Think of it like a classroom:</strong></p>
            <ul>
                <li>üë• Each word is a student</li>
                <li>üôã Students can ask questions to any other student</li>
                <li>üìù Multiple teachers (heads) guide different discussions</li>
                <li>üéì Final understanding comes from combining all perspectives</li>
            </ul>
        </div>

        <!-- Slide 10: Context Size -->
        <div class="slide">
            <h2>Context Windows ü™ü</h2>
            <h3>How much can the model remember at once?</h3>
            <div class="visual-example">
                <p><strong>Evolution of context:</strong></p>
                <p>üìè RNN: ~100 words (forgets quickly)</p>
                <p>üìê LSTM: ~500 words (better memory)</p>
                <p>üìä Early Transformers: ~2,000 tokens</p>
                <p>üìà GPT-4: ~32,000 tokens</p>
                <p>üöÄ Claude: ~100,000+ tokens!</p>
            </div>
            <p><strong>Why does context size matter?</strong></p>
            <ul>
                <li>üìö Can read entire books</li>
                <li>üí¨ Remember long conversations</li>
                <li>üîç Analyze complex documents</li>
                <li>üß© Solve problems requiring lots of information</li>
            </ul>
        </div>

        <!-- Slide 11: Training LLMs -->
        <div class="slide">
            <h2>How Do We Train LLMs? üèãÔ∏è</h2>
            <h3>Teaching models to predict the next word</h3>
            <div class="visual-example">
                <p><strong>Training Example:</strong></p>
                <p>Input: "The cat sat on the"</p>
                <p>Target: "mat"</p>
                <p style="margin-top: 20px;">
                    Model predicts: 
                    <span class="token">floor (30%)</span>
                    <span class="token">mat (25%)</span>
                    <span class="token">chair (20%)</span>
                    <span class="token">table (15%)</span>
                    <span class="token">other (10%)</span>
                </p>
            </div>
            <p><strong>Training Process:</strong></p>
            <ul>
                <li>üìñ Show billions of text examples</li>
                <li>üéØ Model tries to predict next word</li>
                <li>‚ùå Calculate how wrong it was</li>
                <li>üîß Adjust weights to be less wrong</li>
                <li>üîÑ Repeat millions of times!</li>
            </ul>
        </div>

        <!-- Slide 12: Next Token Prediction -->
        <div class="slide">
            <h2>From Next Word to Conversations üí¨</h2>
            <h3>How does predicting words become ChatGPT?</h3>
            <div class="visual-example">
                <p><strong>User:</strong> "What is the capital of France?"</p>
                <p><strong>Model thinks:</strong></p>
                <p>"What is the capital of France? The"</p>
                <p>"What is the capital of France? The capital"</p>
                <p>"What is the capital of France? The capital of"</p>
                <p>"What is the capital of France? The capital of France"</p>
                <p>"What is the capital of France? The capital of France is"</p>
                <p>"What is the capital of France? The capital of France is Paris"</p>
            </div>
            <p><strong>Magic:</strong> By predicting one word at a time, it generates complete responses!</p>
            <p>It's like autocomplete on steroids! üí™</p>
        </div>

        <!-- Slide 13: RLHF -->
        <div class="slide">
            <h2>Reinforcement Learning from Human Feedback (RLHF) üë®‚Äçüè´</h2>
            <h3>Teaching models to be helpful, harmless, and honest</h3>
            <div class="visual-example">
                <p><strong>Problem:</strong> Raw language models just predict text, they don't know what's helpful!</p>
                <p style="margin: 20px 0;"><strong>Solution: Three steps</strong></p>
            </div>
            <p><strong>1. Supervised Fine-Tuning:</strong></p>
            <ul>
                <li>Humans write good responses</li>
                <li>Model learns to copy this style</li>
            </ul>
            <p><strong>2. Reward Model Training:</strong></p>
            <ul>
                <li>Model generates multiple responses</li>
                <li>Humans rank them (best to worst)</li>
                <li>Train a model to predict human preferences</li>
            </ul>
            <p><strong>3. Reinforcement Learning:</strong></p>
            <ul>
                <li>Model generates responses</li>
                <li>Reward model scores them</li>
                <li>Model learns to maximize scores</li>
            </ul>
        </div>

        <!-- Slide 14: Key Insights -->
        <div class="slide">
            <h2>Key Takeaways for Scientists üî¨</h2>
            <div class="visual-example">
                <h3>What makes LLMs powerful:</h3>
                <p>‚ú® <strong>Scale:</strong> Billions of parameters trained on trillions of words</p>
                <p>üß† <strong>Attention:</strong> Can focus on relevant context</p>
                <p>üìö <strong>Transfer Learning:</strong> Knowledge from training applies to new tasks</p>
                <p>üéØ <strong>Fine-tuning:</strong> Can be specialized for specific domains</p>
            </div>
            <h3>How to use them better:</h3>
            <ul>
                <li><strong>Be specific:</strong> Clear instructions get better results</li>
                <li><strong>Provide context:</strong> Give relevant background information</li>
                <li><strong>Use examples:</strong> Show what you want (few-shot learning)</li>
                <li><strong>Iterate:</strong> Refine your prompts based on outputs</li>
                <li><strong>Understand limitations:</strong> No real-time data, can hallucinate</li>
            </ul>
        </div>

        <!-- Slide 15: Summary -->
        <div class="slide">
            <h2>Summary: From Neurons to ChatGPT üéØ</h2>
            <div class="visual-example">
                <h3>Our Journey:</h3>
                <p>1Ô∏è‚É£ <strong>Simple neurons</strong> make decisions</p>
                <p>2Ô∏è‚É£ <strong>Networks</strong> combine many decisions</p>
                <p>3Ô∏è‚É£ <strong>RNNs</strong> add memory</p>
                <p>4Ô∏è‚É£ <strong>Attention</strong> focuses on what matters</p>
                <p>5Ô∏è‚É£ <strong>Transformers</strong> process everything at once</p>
                <p>6Ô∏è‚É£ <strong>Training</strong> teaches next-word prediction</p>
                <p>7Ô∏è‚É£ <strong>RLHF</strong> makes them helpful</p>
            </div>
            <h3 class="center">üéâ Now you understand LLMs! üéâ</h3>
            <p class="center" style="margin-top: 30px;">
                <strong>Remember:</strong> These are tools to augment your expertise, not replace it!
            </p>
            <p class="center" style="font-size: 1.1em; color: #5e72e4;">
                Happy experimenting! üöÄ
            </p>
        </div>

        <!-- Navigation -->
        <div class="navigation">
            <button id="prevBtn" onclick="changeSlide(-1)">‚Üê Previous</button>
            <div class="slide-number">
                <span id="slideNumber">1</span> / <span id="totalSlides">15</span>
            </div>
            <button id="nextBtn" onclick="changeSlide(1)">Next ‚Üí</button>
        </div>
    </div>

    <script>
        let currentSlide = 0;
        const slides = document.querySelectorAll('.slide');
        const totalSlides = slides.length;
        document.getElementById('totalSlides').textContent = totalSlides;

        function showSlide(n) {
            slides[currentSlide].classList.remove('active');
            currentSlide = (n + totalSlides) % totalSlides;
            slides[currentSlide].classList.add('active');
            
            document.getElementById('slideNumber').textContent = currentSlide + 1;
            
            // Update button states
            document.getElementById('prevBtn').disabled = currentSlide === 0;
            document.getElementById('nextBtn').disabled = currentSlide === totalSlides - 1;
        }

        function changeSlide(direction) {
            showSlide(currentSlide + direction);
        }

        // Keyboard navigation
        document.addEventListener('keydown', (e) => {
            if (e.key === 'ArrowLeft' && currentSlide > 0) changeSlide(-1);
            if (e.key === 'ArrowRight' && currentSlide < totalSlides - 1) changeSlide(1);
        });

        // Initialize
        showSlide(0);
    </script>
</body>
</html>